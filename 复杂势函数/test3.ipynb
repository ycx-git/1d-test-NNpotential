{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output  # 引入 clear_output\n",
    "# torch.manual_seed(seed=42)  \n",
    "\n",
    "os.makedirs(\"fun_images\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num=4\n",
    "hidden_num=128\n",
    "\n",
    "class Mynetwork(nn.Module):\n",
    "    def __init__(self,input_num=1 , out_num=1,hidden_num=512):\n",
    "        super().__init__()\n",
    "        self.MLP=nn.Sequential(\n",
    "            nn.Linear(input_num, hidden_num),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_num,hidden_num),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_num,hidden_num),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_num,hidden_num),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_num,out_num),\n",
    "        )\n",
    "        pass\n",
    "    def forward(self,x):\n",
    "        return self.MLP(x)+self.MLP(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential(x):\n",
    "    poten=2*x**2\n",
    "    return poten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要适当减小,x_M=sqrt(h_bar/(m*w)*(2n+1)),考虑要>10x_M,700sqrt(h_bar/\\omega*m)\n",
    "h_bar=1\n",
    "m=1\n",
    "b_lap:float=-h_bar**2/(2*m)\n",
    "\n",
    "# 同时对于库伦势函数, 取e=1, 4\\pi\\epsilon_0=1, E_n=-1/(2n^2)\n",
    "dtype=torch.float32\n",
    "device=torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs(f'./model_para_{layer_num}_{hidden_num}_{dtype}', exist_ok=True)\n",
    "La=-10\n",
    "Lb =10\n",
    "L=Lb-La  # domain length\n",
    "N = 3000   # number of interior points # 对时间成本来说几乎是平方量级\n",
    "h :float= L / (N+1)\n",
    "grid=torch.linspace(La,Lb,N+2,dtype=dtype,device=device,requires_grad=True)\n",
    "grid=grid[1:-1].unsqueeze(-1)\n",
    "\n",
    "en_num=20\n",
    "extend_num=0\n",
    "epoch=50000\n",
    "lr=0.01\n",
    "# 先给出固定的矩阵元素\n",
    "diag = -2.0 / h**2 * torch.ones(N,device=device) * b_lap\n",
    "off_diag = 1.0 / h**2 * torch.ones(N - 1,device=device) * b_lap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 势函数演示图像\n",
    "x_test=torch.linspace(La, Lb, N+2)\n",
    "f1_test=potential(x_test)\n",
    "plt.plot(x_test.numpy(), f1_test.numpy())\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算初始的本征值\n",
    "V_diag=potential(grid)\n",
    "A = torch.diag(diag) + torch.diag(off_diag,diagonal=1) + torch.diag(off_diag, diagonal=-1)+torch.diag(V_diag.flatten())\n",
    "eigenvalues= torch.linalg.eigvalsh(A)\n",
    "\n",
    "print('initial eigenvalues check:')\n",
    "print(eigenvalues[:en_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######----------------------------------------------\n",
    "real_en=eigenvalues[:en_num].detach()\n",
    "######----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Mynetwork().to(device=device,dtype=dtype)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=50,threshold=1e-4)\n",
    "loss_fn=nn.MSELoss()\n",
    "\n",
    "loss_list=[]\n",
    "init_time=time.time()\n",
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    V_diag=model(grid)\n",
    "    A = torch.diag(diag) + torch.diag(off_diag,diagonal=1) + torch.diag(off_diag, diagonal=-1)+torch.diag(V_diag.flatten())\n",
    "    eigenvalues= torch.linalg.eigvalsh(A)\n",
    "    \n",
    "    output=eigenvalues[:en_num]\n",
    "    \n",
    "    val_loss=loss_fn(output,real_en)\n",
    "    loss=val_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    os.makedirs(f'./fun_images/V_{La}_{Lb}_{N}_{en_num}', exist_ok=True)\n",
    "    torch.save(V_diag,f'./fun_images/V_{La}_{Lb}_{N}_{en_num}/V_diag_{i}.pth')\n",
    "    \n",
    "    if i%10==0:\n",
    "        # clear_output(wait=True)\n",
    "        print(f'epoch:{i},loss:{loss},time:{time.time()-init_time},lr:{optimizer.param_groups[0][\"lr\"]}')\n",
    "        print('\\nepoch:',i)\n",
    "        print(eigenvalues[:en_num+extend_num])\n",
    "        print(real_en)\n",
    "    if (i+1)%100==0:torch.save(model.state_dict(),f'./model_para_{layer_num}_{hidden_num}_{dtype}/model_para_use_eigvalues_{en_num}_La{La}_Lb{Lb}_N{N}.pth')\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    if optimizer.param_groups[0][\"lr\"] <= 1.1e-8:break\n",
    "final_loss=loss.item()\n",
    "final_time_cost=time.time()-init_time\n",
    "final_epoch=i+1\n",
    "print('terminal epoch: ',i+1)\n",
    "torch.save(model.state_dict(),f'./model_para_{layer_num}_{hidden_num}_{dtype}/model_para_use_eigvalues_{en_num}_La{La}_Lb{Lb}_N{N}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La=-10\n",
    "Lb =10\n",
    "L=Lb-La  # domain length\n",
    "N = 2000   # number of interior points # 对时间成本来说几乎是平方量级\n",
    "h :float= L / (N+1)\n",
    "grid=torch.linspace(La,Lb,N+2,dtype=dtype,device=device)\n",
    "grid=grid[1:-1].unsqueeze(-1)\n",
    "V_NN=model(grid)\n",
    "V_NN=V_NN.cpu().detach().numpy()\n",
    "real_poten=potential(grid)\n",
    "real_poten=real_poten.cpu().detach().numpy()\n",
    "plt.plot(grid.cpu().detach().numpy(),real_poten,label='real')\n",
    "plt.plot(grid.cpu().detach().numpy(),V_NN,label='NN')\n",
    "plt.title(f'time cost: {final_time_cost:.2f}s  ,  epoch: {final_epoch}  ,  loss: {final_loss:.4e}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La=-1\n",
    "Lb =1\n",
    "L=Lb-La  # domain length\n",
    "N = 200   # number of interior points # 对时间成本来说几乎是平方量级\n",
    "h :float= L / (N+1)\n",
    "grid=torch.linspace(La,Lb,N+2,dtype=dtype,device=device)\n",
    "grid=grid[1:-1].unsqueeze(-1)\n",
    "V_NN=model(grid)\n",
    "V_NN=V_NN.cpu().detach().numpy()\n",
    "real_poten=potential(grid)\n",
    "real_poten=real_poten.cpu().detach().numpy()\n",
    "plt.plot(grid.cpu().detach().numpy(),real_poten,label='real')\n",
    "plt.plot(grid.cpu().detach().numpy(),V_NN,label='NN')\n",
    "plt.title(f'time cost: {final_time_cost:.2f}s  ,  epoch: {final_epoch}  ,  loss: {final_loss:.4e}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(f'./V_NN_value_{sym}_{layer_num}_{hidden_num}_{dtype}', exist_ok=True)\n",
    "# torch.save(V_NN,f'./V_NN_value_{sym}_{layer_num}_{hidden_num}_{dtype}/V_NN_use_eigvalues_{en_num}_La{La}_Lb{Lb}_N{N}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=V_NN-real_poten\n",
    "mean_error=np.mean(np.abs(error))\n",
    "max_error=np.max(np.abs(error))\n",
    "print('mean_error:',mean_error)\n",
    "print('max_error:',max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
