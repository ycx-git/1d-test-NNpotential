{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Mynetwork(nn.Module):\n",
    "    def __init__(self,input_num=1 , out_num=1,hidden_num=32):\n",
    "        super().__init__()\n",
    "        self.MLP=nn.Sequential(\n",
    "            nn.Linear(input_num, hidden_num),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_num,hidden_num),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_num,out_num),\n",
    "        )\n",
    "        pass\n",
    "    def forward(self,x):\n",
    "        return self.MLP(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([[3/2,-1/2],[-1/2,3/2]])\n",
    "\n",
    "eigenvalues= torch.linalg.eigvalsh(A)\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2741],\n",
      "        [0.3247]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dtype=torch.float32\n",
    "NN=Mynetwork(1,1).to(dtype=dtype)\n",
    "input=torch.tensor([[1.0],[2.0]],dtype=dtype)\n",
    "print(NN(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2741, -0.5000],\n",
      "        [-0.5000,  0.3247]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output=NN(input)\n",
    "diag=torch.diag(output.flatten())\n",
    "B=torch.tensor([[0,-1/2],[-1/2,0]],dtype=torch.float32)+diag\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2012,  0.8000], grad_fn=<LinalgEighBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pre_eig=torch.linalg.eigvalsh(B)\n",
    "print(pre_eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2012,  0.8000], grad_fn=<LinalgEighBackward0>)\n",
      "1.2012443542480469\n",
      "tensor([1.0500, 2.2083], grad_fn=<LinalgEighBackward0>)\n",
      "0.04997670650482178\n",
      "tensor([0.9667, 2.1170], grad_fn=<LinalgEighBackward0>)\n",
      "0.03326481580734253\n",
      "tensor([0.9771, 2.1287], grad_fn=<LinalgEighBackward0>)\n",
      "0.022867143154144287\n",
      "tensor([1.1202, 2.2926], grad_fn=<LinalgEighBackward0>)\n",
      "0.1201789379119873\n",
      "tensor([1.0487, 2.2060], grad_fn=<LinalgEighBackward0>)\n",
      "0.0487445592880249\n",
      "tensor([0.9945, 2.1430], grad_fn=<LinalgEighBackward0>)\n",
      "0.005525171756744385\n",
      "tensor([0.9811, 2.1274], grad_fn=<LinalgEighBackward0>)\n",
      "0.018943488597869873\n",
      "tensor([0.9810, 2.1272], grad_fn=<LinalgEighBackward0>)\n",
      "0.019019722938537598\n",
      "tensor([1.0131, 2.1641], grad_fn=<LinalgEighBackward0>)\n",
      "0.013109803199768066\n",
      "tensor([0.9953, 2.1435], grad_fn=<LinalgEighBackward0>)\n",
      "0.004731297492980957\n",
      "tensor([1.0028, 2.1522], grad_fn=<LinalgEighBackward0>)\n",
      "0.002846240997314453\n",
      "tensor([1.0012, 2.1504], grad_fn=<LinalgEighBackward0>)\n",
      "0.0012464523315429688\n",
      "tensor([0.9991, 2.1479], grad_fn=<LinalgEighBackward0>)\n",
      "0.0009137988090515137\n",
      "tensor([1.0004, 2.1494], grad_fn=<LinalgEighBackward0>)\n",
      "0.0004254579544067383\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "4.673004150390625e-05\n",
      "tensor([1.0000, 2.1489], grad_fn=<LinalgEighBackward0>)\n",
      "2.384185791015625e-05\n",
      "tensor([1.0000, 2.1489], grad_fn=<LinalgEighBackward0>)\n",
      "1.1265277862548828e-05\n",
      "tensor([1.0000, 2.1489], grad_fn=<LinalgEighBackward0>)\n",
      "8.702278137207031e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "6.794929504394531e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "1.0371208190917969e-05\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "3.0994415283203125e-06\n",
      "tensor([1.0000, 2.1489], grad_fn=<LinalgEighBackward0>)\n",
      "6.020069122314453e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "7.867813110351562e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "1.0728836059570312e-05\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "1.3113021850585938e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "1.8477439880371094e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "1.0728836059570312e-06\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "9.5367431640625e-07\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "7.152557373046875e-07\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "5.960464477539062e-07\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "5.960464477539063e-08\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n",
      "tensor([1.0000, 2.1490], grad_fn=<LinalgEighBackward0>)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.Adam(NN.parameters(),lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=20,threshold=1e-4)\n",
    "loss_fn=nn.L1Loss()\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output=NN(input)\n",
    "    diag=torch.diag(output.flatten())\n",
    "    B=torch.tensor([[0,-1/2],[-1/2,0]],dtype=torch.float32)+diag\n",
    "    pre_eig=torch.linalg.eigvalsh(B)\n",
    "    \n",
    "    loss=loss_fn(eigenvalues[0],pre_eig[0])\n",
    "    loss.backward()\n",
    "    # print(NN.MLP[0].weight.grad)\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    if i %10==0:\n",
    "        print(pre_eig)\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
