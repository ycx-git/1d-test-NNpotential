{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[[ 1. -1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(5))\n",
    "a=np.linalg.inv([[1,1],[0,1]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a=time.time()\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5965,  1.8596, -2.3153, -2.0749, -1.5420])\n",
      "tensor([1.5965, 1.8596])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scale=3\n",
    "para_num=5\n",
    "a=2*scale*torch.rand(para_num)-scale\n",
    "print(a)\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[51, 58, 89, 23],\n",
      "        [93, 71, 11, 47],\n",
      "        [23, 59, 23, 36]])\n",
      "tensor([[11, 96,  2, 58],\n",
      "        [70, 93, 30, 31],\n",
      "        [40, 59, 12, 27]])\n",
      "tensor([[91, 25, 29, 15],\n",
      "        [88, 90, 63,  1],\n",
      "        [41, 50, 34, 73]])\n",
      "tensor([[51, 58, 89, 23],\n",
      "        [93, 71, 11, 47],\n",
      "        [23, 59, 23, 36],\n",
      "        [11, 96,  2, 58],\n",
      "        [70, 93, 30, 31],\n",
      "        [40, 59, 12, 27],\n",
      "        [91, 25, 29, 15],\n",
      "        [88, 90, 63,  1],\n",
      "        [41, 50, 34, 73]])\n",
      "tensor([[51, 58, 89, 23],\n",
      "        [93, 71, 11, 47],\n",
      "        [23, 59, 23, 36],\n",
      "        [11, 96,  2, 58],\n",
      "        [70, 93, 30, 31],\n",
      "        [40, 59, 12, 27],\n",
      "        [91, 25, 29, 15],\n",
      "        [88, 90, 63,  1],\n",
      "        [41, 50, 34, 73]])\n",
      "tensor([[[51, 58, 89, 23],\n",
      "         [93, 71, 11, 47],\n",
      "         [23, 59, 23, 36]],\n",
      "\n",
      "        [[11, 96,  2, 58],\n",
      "         [70, 93, 30, 31],\n",
      "         [40, 59, 12, 27]],\n",
      "\n",
      "        [[91, 25, 29, 15],\n",
      "         [88, 90, 63,  1],\n",
      "         [41, 50, 34, 73]]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randint(0,100,(3,4))\n",
    "b=torch.randint(0,100,(3,4))\n",
    "c=torch.randint(0,100,(3,4))\n",
    "e=torch.concatenate((a,b,c),dim=0)\n",
    "f=torch.stack((a,b,c),dim=0)\n",
    "g=torch.concatenate((f,f),dim=0)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(e)\n",
    "list=[a,b,c]\n",
    "k=torch.cat(list,dim=0)\n",
    "print(k)\n",
    "print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[79, 46, 65, 58],\n",
      "        [64,  6, 46, 44],\n",
      "        [ 6, 79,  1, 48]])\n",
      "tensor([[20, 54],\n",
      "        [33, 56],\n",
      "        [49, 25]])\n",
      "tensor([[79, 46, 65, 58, 20, 54],\n",
      "        [64,  6, 46, 44, 33, 56],\n",
      "        [ 6, 79,  1, 48, 49, 25]])\n",
      "tensor([79, 46, 65, 58, 64,  6, 46, 44])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randint(0,100,(3,4))\n",
    "b=torch.randint(0,100,(3,2))\n",
    "c=torch.concatenate((a,b),dim=-1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(a[0:2].view(-1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小的 2 个元素: tensor([1.0000, 1.5000])\n",
      "对应的索引: tensor([5, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 (3, 4) 的张量\n",
    "tensor = torch.tensor([[10, 20, 30, 40],\n",
    "                       [5, 1, 25, 35],\n",
    "                       [1.5, 2, 3, 4]], dtype=torch.float32)\n",
    "\n",
    "# 选取最小的 2 个元素\n",
    "values, indices = torch.topk(tensor.view(-1), k=2, largest=False)\n",
    "\n",
    "print(\"最小的 2 个元素:\", values)\n",
    "print(\"对应的索引:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9514, -0.0060,  0.0041])\n"
     ]
    }
   ],
   "source": [
    "width=torch.tensor([4,0.01,0.01])\n",
    "alpha_list=2*width*torch.rand(3)-width\n",
    "print(alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3091835/512266182.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  a=torch.load(f'./target_alpha/alpha_{epoch}_{batch}_{count}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.9542e-01, -1.0932e-02,  7.4956e-03, -9.4731e-04,  8.9720e-03],\n",
      "         [ 1.6053e-01,  7.6751e-02,  9.4413e-03,  7.1351e-03,  1.7106e-03],\n",
      "         [ 7.6759e-02, -1.4104e-02, -8.7482e-03, -5.2837e-03,  5.4952e-05],\n",
      "         [ 1.0731e-01,  2.5833e-02, -1.8295e-04, -2.8747e-03,  6.3025e-03],\n",
      "         [ 1.8183e-01,  9.4636e-02,  6.8653e-03, -4.0535e-03,  3.8740e-03],\n",
      "         [ 1.0170e+00,  8.0649e-02,  5.4375e-03, -6.8647e-03,  6.6465e-03],\n",
      "         [ 1.2206e+00, -3.5588e-02,  2.8816e-03,  1.1705e-03,  9.1798e-03],\n",
      "         [ 1.6783e+00, -7.4236e-02, -7.8886e-03,  8.3530e-03,  9.7827e-03],\n",
      "         [ 1.3856e+00,  6.0639e-02,  8.5798e-03, -7.3877e-03,  8.1025e-03],\n",
      "         [ 1.1044e+00, -7.3485e-02, -2.7196e-03,  1.0904e-03, -9.3546e-03],\n",
      "         [ 7.2959e-01,  4.4877e-02,  3.1615e-04,  8.6137e-03,  2.6459e-03],\n",
      "         [ 1.6527e-01, -8.4722e-02,  6.4335e-03, -7.5076e-03, -6.2747e-03],\n",
      "         [ 8.4470e-01, -8.1355e-02, -4.1135e-03,  6.0192e-03,  4.4913e-03],\n",
      "         [ 2.4613e-01, -6.1400e-02,  9.5282e-03, -1.4203e-03, -5.5762e-03],\n",
      "         [ 1.4696e+00, -5.2512e-02, -1.1826e-03,  1.9684e-03,  8.1504e-03],\n",
      "         [ 7.0464e-01,  3.3509e-02,  6.1636e-04,  4.4441e-03,  5.8841e-03]],\n",
      "\n",
      "        [[ 6.3154e-02,  7.6598e-02, -9.2930e-03,  9.8252e-04, -3.0514e-03],\n",
      "         [ 4.4928e-01,  8.9612e-02,  8.0705e-04, -8.1740e-03,  4.6385e-03],\n",
      "         [ 9.2861e-02, -8.8096e-02,  6.8713e-03, -8.5712e-03,  8.8634e-03],\n",
      "         [ 7.4916e-02, -4.6823e-02, -7.0372e-03,  3.7678e-03,  1.2674e-03],\n",
      "         [ 7.2744e-01, -2.9285e-02,  3.6064e-03,  7.9685e-03,  2.6337e-03],\n",
      "         [ 1.0335e+00,  9.9951e-02, -6.9647e-03, -6.7282e-03, -8.8569e-03],\n",
      "         [ 8.6197e-01, -2.6049e-02,  3.6183e-03, -7.5928e-03,  9.6066e-03],\n",
      "         [ 7.9759e-01, -7.6014e-02, -5.6956e-03,  4.2981e-03,  5.1827e-03],\n",
      "         [ 6.0383e-01, -3.8424e-02, -3.8702e-03,  7.3780e-03, -7.8366e-03],\n",
      "         [ 2.0031e-01, -1.3919e-02,  3.6760e-03,  3.1786e-04, -9.6956e-03],\n",
      "         [ 2.5560e-01, -2.7892e-02, -8.7144e-03, -6.9092e-03, -5.6927e-03],\n",
      "         [ 2.8474e-01, -9.9391e-02,  5.4677e-03,  1.8622e-03, -9.6685e-03],\n",
      "         [ 1.5060e-01,  2.4529e-02, -5.0671e-03, -1.0456e-03, -7.2348e-03],\n",
      "         [ 4.2383e-01,  7.9651e-02, -2.4055e-03,  4.2717e-03,  9.8818e-03],\n",
      "         [ 5.6255e-01, -8.7554e-02, -7.9443e-03,  2.5065e-03, -7.4732e-03],\n",
      "         [ 4.1465e-01, -9.1218e-02, -7.1120e-03,  6.5524e-03, -6.1239e-03]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "tensor([[[  23.8582,   24.1849,   24.8175,   25.7226,   26.8624,   28.2021,\n",
      "            28.4589,   28.8267,   29.5325,   29.7113,   30.5302,   31.3650],\n",
      "         [  23.1406,   23.4714,   24.0892,   24.9343,   25.9534,   26.2462,\n",
      "            26.6158,   27.1056,   27.2937,   28.2045,   28.3611,   29.2870],\n",
      "         [ -48.3396,  -48.3283,  -48.3057,  -48.2717,  -48.2265,  -48.1699,\n",
      "           -48.1021,  -48.0229,  -47.9324,  -47.8306,  -47.7176,  -47.5932],\n",
      "         [  12.7900,   13.2033,   13.9599,   14.9781,   16.1937,   16.2618,\n",
      "            16.7636,   17.5620,   17.6501,   18.8054,   19.0522,   19.9372],\n",
      "         [  22.8147,   23.0574,   23.5225,   24.1787,   24.9945,   25.7768,\n",
      "            25.9424,   26.0576,   26.5878,   27.0005,   27.3231,   28.1514],\n",
      "         [  57.2972,   57.4254,   57.6806,   58.0600,   58.5600,   59.1761,\n",
      "            59.9030,   60.7351,   61.6669,   61.7126,   61.8488,   62.1194],\n",
      "         [  63.7410,   63.8990,   64.2133,   64.6807,   65.2968,   66.0560,\n",
      "            66.9519,   67.9777,   69.1265,   69.2102,   69.3768,   69.7082],\n",
      "         [  80.8842,   81.0308,   81.3229,   81.7585,   82.3344,   83.0469,\n",
      "            83.8915,   84.8632,   85.9567,   86.9090,   87.0622,   87.1667],\n",
      "         [  72.3485,   72.4723,   72.7190,   73.0867,   73.5727,   74.1737,\n",
      "            74.8858,   75.7047,   76.6258,   77.3310,   77.4613,   77.6444],\n",
      "         [-845.3975, -845.3871, -845.3663, -845.3351, -845.2935, -845.2415,\n",
      "          -845.1791, -845.1064, -845.0232, -844.9296, -844.8256, -844.7112],\n",
      "         [  44.9420,   45.0867,   45.3733,   45.7969,   46.3506,   47.0262,\n",
      "            47.8152,   48.7004,   48.7086,   48.8537,   49.1570,   49.6042],\n",
      "         [-639.9273, -639.9169, -639.8960, -639.8646, -639.8228, -639.7706,\n",
      "          -639.7079, -639.6348, -639.5513, -639.4573, -639.3528, -639.2379],\n",
      "         [  37.3477,   37.4956,   37.7893,   38.2243,   38.7949,   39.4941,\n",
      "            40.3139,   41.2465,   41.6055,   41.7624,   42.0737,   42.2838],\n",
      "         [-510.1779, -510.1674, -510.1465, -510.1150, -510.0731, -510.0208,\n",
      "          -509.9579, -509.8846, -509.8008, -509.7065, -509.6018, -509.4865],\n",
      "         [  68.9679,   69.1033,   69.3731,   69.7751,   70.3063,   70.9631,\n",
      "            71.7409,   72.6349,   73.6401,   74.3289,   74.4709,   74.7511],\n",
      "         [  45.7931,   45.9736,   46.3309,   46.8583,   47.5467,   48.3854,\n",
      "            49.3633,   50.3125,   50.4689,   50.5058,   50.8878,   51.4501]],\n",
      "\n",
      "        [[-259.7231, -259.7125, -259.6913, -259.6595, -259.6171, -259.5642,\n",
      "          -259.5006, -259.4264, -259.3417, -259.2464, -259.1404, -259.0239],\n",
      "         [  30.6153,   30.7556,   31.0329,   31.4414,   31.9730,   32.6190,\n",
      "            33.3701,   33.9159,   34.0703,   34.2173,   34.3746,   34.8207],\n",
      "         [   1.2654,    1.7555,    2.6357,    3.8008,    4.9712,    5.1758,\n",
      "             5.5797,    6.6240,    6.7115,    7.9562,    8.3750,    8.9299],\n",
      "         [   1.2429,    1.5436,    2.0827,    2.7936,    3.4723,    3.6285,\n",
      "             3.8323,    4.4521,    4.5559,    5.2432,    5.5549,    5.8173],\n",
      "         [  37.8285,   37.9730,   38.2594,   38.6826,   39.2356,   39.9103,\n",
      "            40.6980,   41.5628,   41.5897,   41.7160,   42.0189,   42.4657],\n",
      "         [-861.1819, -861.1715, -861.1507, -861.1195, -861.0779, -861.0259,\n",
      "          -860.9635, -860.8908, -860.8076, -860.7140, -860.6100, -860.4957],\n",
      "         [  45.5146,   45.6845,   46.0218,   46.5219,   47.1783,   47.9832,\n",
      "            48.9281,   50.0040,   50.5264,   50.7083,   51.0691,   51.2021],\n",
      "         [  35.7591,   35.9142,   36.2218,   36.6773,   37.2742,   38.0048,\n",
      "            38.8607,   39.8331,   40.1010,   40.2663,   40.5936,   40.9136],\n",
      "         [-644.8022, -644.7917, -644.7709, -644.7396, -644.6978, -644.6457,\n",
      "          -644.5831, -644.5100, -644.4266, -644.3327, -644.2284, -644.1136],\n",
      "         [-882.0090, -881.9986, -881.9778, -881.9466, -881.9051, -881.8531,\n",
      "          -881.7908, -881.7180, -881.6349, -881.5413, -881.4374, -881.3231],\n",
      "         [-587.9142, -587.9037, -587.8828, -587.8514, -587.8096, -587.7573,\n",
      "          -587.6945, -587.6213, -587.5376, -587.4435, -587.3389, -587.2239],\n",
      "         [-870.5175, -870.5071, -870.4863, -870.4551, -870.4135, -870.3615,\n",
      "          -870.2992, -870.2264, -870.1432, -870.0497, -869.9457, -869.8314],\n",
      "         [-668.5652, -668.5547, -668.5339, -668.5026, -668.4608, -668.4087,\n",
      "          -668.3461, -668.2730, -668.1896, -668.0957, -667.9914, -667.8766],\n",
      "         [  40.6590,   40.9536,   41.5306,   42.3684,   43.4409,   44.7211,\n",
      "            45.7748,   46.0998,   46.1835,   46.7329,   47.6454,   47.8057],\n",
      "         [-666.7150, -666.7046, -666.6837, -666.6524, -666.6107, -666.5585,\n",
      "          -666.4959, -666.4229, -666.3394, -666.2455, -666.1412, -666.0264],\n",
      "         [-502.6747, -502.6642, -502.6432, -502.6118, -502.5699, -502.5176,\n",
      "          -502.4547, -502.3814, -502.2976, -502.2034, -502.0986, -501.9834]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3091835/512266182.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  b=torch.load(f'./data_eigenvalue/eigenvalues_{epoch}_{batch}_{count}.pt')\n"
     ]
    }
   ],
   "source": [
    "# torch.save(target_alpha,f'./target_alpha/alpha_{epoch}_{batch}_{count}.pt')\n",
    "# torch.save(data_eig,f'./data_eigenvalue/eigenvalues_{epoch}_{batch}_{count}.pt')\n",
    "epoch=2\n",
    "batch=16\n",
    "count=1\n",
    "a=torch.load(f'./target_alpha/alpha_{epoch}_{batch}_{count}.pt')\n",
    "b=torch.load(f'./data_eigenvalue/eigenvalues_{epoch}_{batch}_{count}.pt')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 1.])\n",
      "tensor([1., 1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.tensor([1,2,3,4,5])-3\n",
    "mask1=(x>0).float()\n",
    "mask2=(x<0).float()\n",
    "print(mask1)\n",
    "print(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3., 12.], grad_fn=<MulBackward0>)\n",
      "tensor([ 6., 12.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义一个示例函数\n",
    "x = torch.tensor([1.0 , 2.0], requires_grad=True)  # 确保启用梯度计算\n",
    "y = x**3  # 示例函数 y = x^3\n",
    "\n",
    "# 计算一阶导数\n",
    "grad_1 = torch.autograd.grad(y, x ,grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "\n",
    "print(grad_1)  # 输出 12.0\n",
    "# 计算二阶导数\n",
    "grad_2 = torch.autograd.grad(grad_1, x,grad_outputs=torch.ones_like(x))[0]\n",
    "\n",
    "print( grad_2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
